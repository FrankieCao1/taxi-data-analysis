{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "_KgKWO_tgce7",
        "65AX_6UR1b_h"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Plan\n",
        "\n",
        "1. Preprocess data\n",
        "\n",
        "2. Find variables with high correlation with tip amount variable\n",
        "\n",
        "3. Use a RandomForestRegressor + RandomizedSearchCV to build a prediction model\n",
        "\n",
        "4. Find feature importance of variables after model is finished training\n",
        "\n",
        "5. Summarize results"
      ],
      "metadata": {
        "id": "p7Y4KG4R4rx5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data preprocessing"
      ],
      "metadata": {
        "id": "_KgKWO_tgce7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GQZ-h9kW100a"
      },
      "outputs": [],
      "source": [
        "!unzip cleaned_data.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# concatenate all files into single dataframe\n",
        "alldata = (pd.read_parquet(f\"cleaned_data/1.parquet\")).head(1500000)\n",
        "for i in range(2, 13):\n",
        "  alldata = pd.concat([alldata, (pd.read_parquet(f\"cleaned_data/{i}.parquet\")).head(1500000)])"
      ],
      "metadata": {
        "id": "27Z_Ju9bgJsb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# turn date-time into numerical values\n",
        "alldata['tpep_pickup_datetime'] = pd.to_datetime(alldata['tpep_pickup_datetime']).astype('int64') // 1e9\n",
        "alldata['tpep_dropoff_datetime'] = pd.to_datetime(alldata['tpep_dropoff_datetime']).astype('int64') // 1e9"
      ],
      "metadata": {
        "id": "pS0WqUEo1Mmi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# turn 'N' and 'Y' into 0 and 1\n",
        "alldata[\"store_and_fwd_flag\"] = alldata[\"store_and_fwd_flag\"].map(lambda x: 0 if x == \"N\" else 1)"
      ],
      "metadata": {
        "id": "1is_P9xl1Oqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# drop unwanted columns\n",
        "alldata = alldata.drop(columns=[\"yyyy-mm\", \"Airport_fee\", \"total_amount\"])\n",
        "\n",
        "# fillNA with zeroes\n",
        "alldata[\"airport_fee\"] = alldata[\"airport_fee\"].fillna(0.00)"
      ],
      "metadata": {
        "id": "rMjNFzls1QV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# one-hot encode nominal categories\n",
        "alldata = pd.get_dummies(alldata, columns=['VendorID', 'RatecodeID', 'payment_type'], prefix_sep='_', dtype=int)"
      ],
      "metadata": {
        "id": "sXaznCub1R2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alldata.head()"
      ],
      "metadata": {
        "id": "tSAEj6vW1TJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Variable Correlations"
      ],
      "metadata": {
        "id": "65AX_6UR1b_h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install seaborn"
      ],
      "metadata": {
        "id": "rAyweC8q1d_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# select numerical values\n",
        "numericals = alldata.select_dtypes(\"float\")\n",
        "\n",
        "corr = numericals.corr()[['tip_amount']]\n",
        "sns.heatmap(corr, annot=True)"
      ],
      "metadata": {
        "id": "RxLdUMyP1eZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build a Random Forest model"
      ],
      "metadata": {
        "id": "EJMnmiY21ijK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from scipy.stats import randint\n",
        "\n",
        "# get variables and target\n",
        "X = alldata.drop(\"tip_amount\", axis=1)\n",
        "y = alldata[\"tip_amount\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "forest = RandomForestRegressor(random_state=0, max_features=9, n_jobs=8)\n",
        "\n",
        "# hyperparameters to search for\n",
        "param_dist = {\n",
        "    'n_estimators': randint(100, 250),\n",
        "    'max_depth': [None, 10, 20, 30, 50],\n",
        "    'min_samples_split': randint(2, 7),\n",
        "    'min_samples_leaf': randint(1, 5)\n",
        "}\n",
        "\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=forest,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=5,\n",
        "    cv=2,\n",
        "    scoring='neg_mean_squared_error',\n",
        "    verbose=1,\n",
        "    random_state = 0\n",
        ")\n",
        "\n",
        "# Train the model with random search and find best parameter combination\n",
        "random_search.fit(X_train, y_train)\n",
        "print(f'Best Parameters: {random_search.best_params_}')"
      ],
      "metadata": {
        "id": "2rOaVoBF1laQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the Best Model\n",
        "best_model = random_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "print(f'RMSE: {rmse:.2f}')"
      ],
      "metadata": {
        "id": "GOeMfKUc1nYO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}